%
%
% Kapitel Datensimulation
%
%


\chapter{Datensimulation}

\section{Monte-Carlo-Simulation}
\label{sec:mc_gen}

Ein Vergleich der Ergebnisse aus von CMS gemessenen Daten mit Monte-Carlo-Simula\-tionen ermöglicht es, die Messergebnisse mit Vorhersagen des Standardmodells zu vergleichen. Zusätzlich können Modelle, die nicht dem Standardmodell entsprechen, überprüft werden. Das Ziel der Datensimulation ist es, mithilfe von Zufallsgeneratoren und physikalischer Modelle Pseudodaten zu erzeugen. Diese Pseudodaten haben dasselbe Datenformat wie aufgenommene Daten. Somit können dieselben Analysen sowohl auf gemessene als auch auf simulierte Daten angewendet werden. In diesem Kapitel wird erläutert, wie die in dieser Analyse untersuchten simulierten Ereignisse produziert werden.

\subsection{Produktionskette}

Die Simulation der Daten erfolgt in mehreren, aufeinander aufbauenden Schritten. Diese sind im Einzelnen:

\begin{enumerate}
	\item Numerische Integration des Matrixelementes (ME) des harten Prozesses und Berechnung des Wirkungsquerschnittes.
	\item Ereignisgeneration: Partonen und Leptonen im Anfangs- und Endzustand der harten Interaktion werdenentsprechend der Wahrscheinlichkeitsdichtefunktionen aus Punkt 1 zufalls-generiert.
	\item Modellierung von Teilchenabstrahlungen: Die Abstrahlung von Gluonen und Photonen aus den Teilchen im Anfangs- und Endzustand wird simuliert.
	\item Hadronisierung: Gruppierung von Quarks zu farbneutralen Hadronen.
	\item Hadronischer Zerfall: Der Zerfall von kurzlebigen Teilchen wird reproduziert.
	\item Underlying Event (UE): Hinzufügen von Teilchen im Endzustand, die von Protonrückständen aus dem harten Prozess entstehen.
	\item Pileup: Eine zufällige Anzahl von zusätzlichen, weichen Proton-Proton-Kollisionen wird erzeugt und dem Ereignis hinzugefügt.
	\item Detektorsimulation: Die Wechselwirkung der in Schritt 2 bis 7 produzierten Teilchen mit dem Detektormaterial und die Digitalisierung werden simuliert.
\end{enumerate}

\subsection{Simulation von \texorpdfstring{$t\overline{t}+\gamma$}{ttg} Ereignissen}

Für die Simulation des semimyonischen $t\overline{t}+\gamma$-Signals wurde WHIZARD, ein Leading-Order-Monte-Carlo-Generator, benutzt. Ein Schaubild mit verschiedenen simulierbaren Endzuständen der Monte-Carlo-Generation ist in Abb.\ref{fig:whizard} gezeigt, auf diese soll hier kurz eingegangen werden:

\begin{description}
  \item[2 $\rightarrow$ 3:] Hier werden nur quantenmechanische Interferenzen aus Photonabstrahlungen von Teilchen im Anfangszustand betrachtet. Die Vorteile dieses Modells sind die geringe CPU-Last, die bei der Berechnung der ME anfällt und die genaue Zuordnung der Photonen zum Top-Vertex. Dies beschreibt den Signalprozess jedoch ungenau \cite{Tholen:Master}.
	\item[2 $\rightarrow$ 5:] In diesem Modell ist der Zerfall der Top-Quarks berücksichtigt, und es trägt nun auch die Photonabstrahlung der W-Bosonen und der b-Quarks zum Signal bei. Es stellt einen guten Kompromiss zwischen CPU-Auslastung und genauer Beschreibung der Natur dar und wird in dieser Analyse benutzt.
	\item[2 $\rightarrow$ 7:] Hier werden alle Photonabstrahlungen des harten Prozesses berücksichtigt und die realen Prozesse am präzisesten beschrieben, diese Strategie ist jedoch überaus CPU-intensiv und wird in dieser Analyse nicht weiter verwendet.
\end{description}

\begin{figure}%
\centering
\includegraphics[width=0.7\columnwidth]{bilder/whizard}%
\caption{Strategien der Ereignisgeneration mit WHIZARD. \cite{Tholen:Master}}%
\label{fig:whizard}%
\end{figure}

Zur Ereignisgeneration wird die Partondichteverteilung CTEQ6L1 \cite{Pumplin:CTEQ} und eine variable Renor\-malisierungs- und Faktorisierungsskala benutzt. Diese Skalen werden für jedes Ereignis auf einen Wert von 172,5\,GeV ($m_t$) plus der Transversalenergie des erzeugten Photons festgelegt. Die Teilchenschauer der Anfangs- und Endzustände sowie die Hadronisierung werden von PYTHIA6 \cite{Sjostrand:PYTHIA}, TAUOLA und PHOTOS (beide in \cite{Was:TAUOLA}) simuliert, dabei wird dieselbe Konfiguration wie für das Top-Quark-Paar-Sample (siehe auch Abschnitt \ref{sec:sim_top_paar}) benutzt. \\
An die Teilchen im Endzustand werden bestimmte Anforderungen gestellt, sogenannte \enquote{Produktionsschnitte}. Es wird eine minimale transversale Energie gefordert, um Infrarotdivergenz zu vermeiden und eine Minimaldistanz im $\eta-\Phi$-Raum gegen kollineare Divergenz. In dieser Analyse wird eine minimale Transversalenergie des Photons und beider b-Quarks von 10\,GeV und ein $\Delta R > 0,1$ zwischen dem Photon und jedem anderen Teilchen im Endzustand gefordert. Um Randeffekte zu vermeiden, werden in der Ereignisselektion härtere Schnitte angewendet, siehe Kapitel \ref{sec:selektion}.

\subsection{Simulation des Top-Quark-Paar-Prozesses und der betrachteten Untergründe}
\label{sec:sim_top_paar}

Die meisten Monte-Carlo-Simulationen neben den $t\overline{t}+\gamma$-Ereignissen werden mit \protect\linebreak{MADGRAPH} \cite{Alwall:MADGRAPH} generiert, hier wird die Partondichtefunktion CTEQ6L1 benutzt. Single-Top-Ereignisse werden mit POWHEG \cite{Alioli:POWHEG}, \cite{Re:POWHEG} simuliert, für den Zerfall des $\tau$-Leptons wird TAUOLA benutzt. Die Hadronisierung und die Teilchenschauer werden mit PYTHIA (hadronische Wechselwirkung) sowie PHOTOS (elektromagnetische Wechselwirkung) modelliert.\
Da der Phasenraum der Ereignisse der WHIZARD $t\overline{t}+\gamma$-Simulation im \protect\linebreak{MADGRAPH} $t\overline{t}$-Sample schon abgedeckt ist, werden Ereignisse aus dem $t\overline{t}$-Sample, welche die Produktionsschnitte in WHIZARD auf Partonebene erfüllen, entfernt, um diese Überschneidung zu vermeiden.

\subsection{Detektorsimulation}

Der Durchgang der von den Monte-Carlo-Generatoren erzeugten Teilchen durch die einzelnen Detektorkomponenten sowie die dadurch ausgelösten Signale werden mit GEANT4 \cite{Agostinelli:GEANT} modelliert. GEANT4 simuliert anhand der Detektorgeometrie und des Magnetfeldes das Verhalten der einzelnen Teilchen im Detektor. Dabei werden alle elektromagnetischen und hadronischen Wechselwirkungen mit dem Detektormaterial berücksichtigt, wie z.B. Schauer in den Kalorimetern. Die Ausgabe der Digitalisierung wird gespeichert und in der Rekonstruktion der einzelnen Teilchen verwendet. Diese Rekonstruktion erfolgt mit den gleichen Algorithmen wie die Rekonstruktion experimenteller Daten. Neben der vollständigen Simulation des Detektors (\enquote{FullSim}), die viel Rechenzeit und -aufwand benötigt, wurden auch vereinfachte Modelle zur Detektorsimulation entwickelt (\enquote{FastSim}) \cite{CMS:TDR1}. Dadurch werden die Dauer der Simulation und der benötigte Speicherplatz erheblich reduziert. Die Daten in dieser Analyse werden mittels FullSim prozessiert.


\section{Studie der von WHIZARD generierten Monte-Carlo-Samples}
\label{sec:montecarlo}

Die Studie der von WHIZARD generierten Monte-Carlo-Daten soll zeigen, wie sich der Wirkungsquerschnitt $\sigma = \sigma(d_A^{\gamma}($ des $t\overline{t}+\gamma$-Prozesses sowie das $E_T$-Spektrum $E_T = E_T(d_A^{\gamma})$ der Photonen aus dem harten Prozess durch Variation des angenommenen $d_A^{\gamma}$-Wertes verändert. Dazu wird eine 2-Bin-Analyse (Abschnitt~\ref{sec:ana_twobin}), eine Analyse des Schwerpunktes der $E_T$-Verteilung (Abschnitt~\ref{sec:ana_mean}) sowie die Analyse  einer Exponentialanpassung an das $E_T$-Spektrum (Abschnitt~\ref{sec:ana_slope}) implementiert. Desweiteren soll untersucht werden, welche der Variablen sich am besten eignet, zwischen verschiedenen $d_A^{\gamma}$-Szenarien zu unterscheiden. Durch Verwendung von Generatorteilchen werden Auflösungseffekte durch die Rekonstruktion sowie Akzeptanzeffekte durch die Selektion vermieden.

\subsection{Wirkungsquerschnitt des \texorpdfstring{$t\overline{t}+\gamma$}{ttg}-Prozesses}
\label{sec:wq}

Es wird eine quadratische Abhängigkeit des Wirkungsquerschnittes vom Parameter $d_A^{\gamma}$ erwartet, da $d_A^{\gamma}$ linear in das Matrixelement eingeht und der Wirkungsquerschnitt proportional zum Quadrat des Matrixelementes ist. \\
Mit dem Leading-Order-Monte-Carlo-Generator WHIZARD in der Version 2.1.1 werden zuerst für verschiedene elektrische Dipolmomente in Schritten von 0,01 für $0<d_A^{\gamma}<1$ die Matrixelemente des harten Prozesses generiert. Das Modell $2 \rightarrow 5$ wird implementiert mit zwei W-Bosonen, zwei b-Quarks und einem Photon im Endzustand. Die Matrixelement-Berechnung wird so lange fortgeführt, bis der Unsicherheitsestimator der numerischen Integration 1\% unterschreitet. Die berechneten Wirkungsquerschnitte sind in Abb. \ref{fig:cs_wofit} dargestellt. Eine Anpassung zeigt die erwartete quadratische Abhängigkeit. Auffällig sind die großen Fehler auf den Wirkungsquerschnitt bei den Werten $d_A^{\gamma}=0,06$ und $d_A^{\gamma}=0,95$. Auch eine deutlich längere Berechnung des Matrixelements verringert diese nicht. Es ist derzeit nicht klar, was diesen großen Fehler verursacht. Es wird von einem internen Berechnungsproblem von WHIZARD bei diesen $d_A^{\gamma}$-Werten ausgegangen, da sich die Steuerungsskripte zur Berechnung der verschiedenen Monte-Carlo-Samples ausschließlich im vorgegebenen $d_A^{\gamma}$-Wert unterscheiden.

\begin{figure}%
\centering
\includegraphics[width=0.5\columnwidth]{bilder/crosssectionplot}%
\caption{Wirkungsquerschnitt des $t\overline{t}+\gamma$-Prozesses für $0<d_A^{\gamma}<1$ mit eingezeichneter quadratischer Anpassung.}%
\label{fig:cs_wofit}%
\end{figure}

\subsection{\texorpdfstring{$E_T$}{ET}-Spektrum des Photons}
\label{sec:etphoton}

Aus dem berechneten Matrixelement werden für jeden $d_A^{\gamma}$-Wert 105.000 Ereignisse generiert und im Les-Houches-Event Format (LHEF) abgespeichert \cite{Alwall:LesHouches}. Abbildung \ref{fig:et_gen_galerie} zeigt in halblogarithmischer Auftragung ausgewählte $E_T$-Spektren dieser generierten Ereignisse. Die Erwartung, dass eine höheren Kopplungsstärke $d_A^{\gamma}$ zu härteren Energiespektren führt, bestätigt sich. Im folgenden werden mehrere Ansätze diskutiert, die Abhängigkeit des $E_T$-Spektrums von $d_A^{\gamma}$ zu beschreiben.

\begin{figure}%
\begin{subfigure}[b]{0.4\textwidth}
\includegraphics[width=\textwidth]{bilder/et_gen_0}%
\end{subfigure}
\hspace{0.1\textwidth}
\begin{subfigure}[b]{0.4\textwidth}
\includegraphics[width=\textwidth]{bilder/et_gen_02}%
\end{subfigure}

\begin{subfigure}[b]{0.4\textwidth}
\includegraphics[width=\textwidth]{bilder/et_gen_04}%
\end{subfigure}
\hspace{0.1\textwidth}
\begin{subfigure}[b]{0.4\textwidth}
\includegraphics[width=\textwidth]{bilder/et_gen_06}%
\end{subfigure}

\begin{subfigure}[b]{0.4\textwidth}
\includegraphics[width=\textwidth]{bilder/et_gen_08}%
\end{subfigure}
\hspace{0.1\textwidth}
\begin{subfigure}[b]{0.4\textwidth}
\includegraphics[width=\textwidth]{bilder/et_gen_1}%
\end{subfigure}
\caption{$E_T$-Verteilungen von Monte-Carlo-Daten auf Generator-Level für verschiedene Werte von $d_A^{\gamma}$.}%
\label{fig:et_gen_galerie}%
\end{figure}

\subsubsection{2-Bin-Analyse}
\label{sec:ana_twobin}

Das $E_T$-Spektrum wird in zwei Bereiche aufgeteilt. Der erste Bereich reicht von 0\,GeV bis 100\,GeV, der zweite von 100\,GeV bis 700\,GeV, siehe dazu Abb. \ref{fig:2bin_skizze}. Nun wird das Verhältnis der Anzahl der Photonen in den beiden Bereichen gegen $d_A^{\gamma}$ aufgetragen, siehe Abb. \ref{fig:2bin_plot}. Auf der linken Seite sieht man zwei Messwerte, die nicht dem allgemeinen Verlauf folgen. Dies sind die schon in Kapitel \ref{sec:wq} angesprochenen Messpunkte, die durch irreduzibel große Fehler auf den Wirkungsquerschnitt auffielen und auch in allen anderen Analysemethoden herausstechen. Die Punkte $d_A^{\gamma}=0,06$ und $d_A^{\gamma}=0,95$ werden im folgenden für die Auswertung der verschiedenen Analysemethoden nicht berücksichtigt. Der so bereinigte Plot ist in Abb. \ref{fig:2bin_plot} rechts zu sehen. Die 2-Bin-Analyse stellt einen vielversprechenden Ansatz dar, das härtere Photonenspektrum für größere Kopplungsstärken $d_A^{\gamma}$ zu beschreiben. Auf Generatorniveau ist eine sehr gute Separationskraft vorhanden, der Wertebereich erstreckt sich von $E_{Low} / E_{High} = 3,8$ für $d_A^{\gamma} = 0$ bis $E_{Low} / E_{High} = 2,2$ für $d_A^{\gamma} = 1$ bei einer Unsicherheit durch Statistik von $\Delta E_{Low} / E_{High} \leq 0,03$. 

\begin{figure}%
\centering
\includegraphics[width=0.5\columnwidth]{bilder/2binskizze}%
\caption{Schema der Unterteilung bei der 2-Bin-Analyse.}%
\label{fig:2bin_skizze}%
\end{figure}

\begin{figure}%
\centering
\begin{subfigure}[b]{0.4\textwidth}
  \includegraphics[width=\textwidth]{bilder/twobinplot}%
\end{subfigure}
\hspace{0.1\textwidth}
\begin{subfigure}[b]{0.4\textwidth}
  \includegraphics[width=\textwidth]{bilder/twobinplotv2}%
\end{subfigure}
\caption{Verhältnis der Anzahl der Photonen in Bin 1 und Bin 2. Im rechten Plot sind die Werte für $d_A^{\gamma} = 0,06$ und $d_A^{\gamma} = 0,95$ nicht berücksichtigt.}%
\label{fig:2bin_plot}%
\end{figure}

\subsubsection{\texorpdfstring{$E_T$}{ET}-Mean-Analyse}
\label{sec:ana_mean}

In diesem Ansatz wird der Schwerpunkt der $E_T$-Verteilung betrachtet, dies ist der gewichtete Mittelwert $\overline{E_T}$ dieser Verteilung. Für die Berechnung des gewichteten Mittelwertes und des Fehlers auf diesen Mittelwert werden die folgenden Formeln benutzt:

\begin{align}
\overline{E_T} &= \frac{1}{N} \sum{x_i\cdot \omega_i} \label{eq:mean} \\
\Delta \overline{E_T} &= \frac{\sum{(x_i - \overline{E_T})^2 \cdot \omega_i}}{\sqrt{N}} \ .
\label{eq:meanerror}
\end{align}

Hier ist $x_i$ der Mittelpunkt des i-ten Bins des Histogrammes und $\omega_i$ die Anzahl der Einträge in diesem Bin. $\overline{E_T}$ wird gegen $d_A^{\gamma}$ aufgetragen (siehe Abbildung \ref{fig:mean_plot}). Es ergibt sich eine hohe Separationskraft dieser Variablen auf Generatorniveau, der Wertebereich liegt hier zwischen 34,7 und 53,5\,GeV mit einer Unsicherheit von $\Delta \overline{E_T} \leq 0,22\,GeV$. 

\begin{figure}%
\centering
\includegraphics[width=0.5\columnwidth]{bilder/meanplot}%
\caption{Verlauf des Schwerpunktes der $E_T$-Verteilung.}%
\label{fig:mean_plot}%
\end{figure}

\subsubsection{Analyse der Exponentialanpassung der \texorpdfstring{$E_T$}{ET}-Verteilung}
\label{sec:ana_slope}

\begin{figure}%
\centering
\includegraphics[width=0.5\columnwidth]{bilder/slopeskizze}%
\caption{Skizze zum Prinzip der Exponentialanpassung.}%
\label{fig:slope_skizze}%
\end{figure}

Hier wird die Anpassung einer Exponentialkurve an die $E_T$-Verteilung betrachtet. Wie in Abb. \ref{fig:slope_skizze} zu sehen ist, kann die Verteilung im Bereich zwischen 100\,GeV und 225\,GeV durch eine logarithmische Funktion

\begin{equation}
N(x) = N_0\cdot e^{\lambda \cdot x}
\label{eq:expofit}
\end{equation}

beschrieben werden. Für jeden $d_A^{\gamma}$-Wert wird nun an das $E_T$-Spektrum eine Exponentialfunktion angepasst und der Wert von $\lambda$ gegen $d_A^{\gamma}$ aufgetragen. Dieser Plot ist in Abb.~\ref{fig:slope_plot} zu sehen. Ein deutlicher Trend lässt sich erkennen. Die $\lambda$-Werte reichen von -0,0115 bis -0,0218 bei einer Unsicherheit von $\Delta \lambda \leq 0,00053$.

\begin{figure}%
\centering
\includegraphics[width=0.5\columnwidth]{bilder/slopeplot}%
\caption{Verlauf des Exponentialkoeffizienten $\lambda$ der Anpassung an die $E_T$-Verteilung.}%
\label{fig:slope_plot}%
\end{figure}

\subsubsection{Ensemblestudie}
\label{sec:ensemble}

Um bei der Analyse der Exponentialanpassung die Abhängigkeit der Unsicherheit von der Anzahl der Ereignisse $N$ zu ermitteln, wird eine Ensemblestudie auf Generatorniveau durchgeführt. Das Vorgehen dieser Studie wird im Folgenden beschrieben. \\
Zunächst wird mit der verfügbaren Statistik von 105000 Ereignissen, das entspricht einer integrierten Luminosität von 36,2\,fb$^{-1}$, die oben beschriebene Analyse der Exponentialanpassung an die $E_T$-Verteilung durchgeführt und der Parameter $\lambda$ bestimmt. Im nächsten Schritt wird diese Verteilung auf verschiedene Luminositätsszenarien skaliert. Ein Pseudoexperiment wird erstellt, welches durch binweises poissonverteiltes Neuwürfeln um den Mittelwert der skalierten Verteilung erhalten wird, siehe Abbildung \ref{fig:ensemble}. Die so neu erstellte Verteilung ist ein möglicher experimenteller Ablauf bei der gewählten Luminosität. Anschließend wird eine Exponentialanpassung durchgeführt und der so bestimmte Wert von $\lambda$ histogrammiert. Dies wird für alle Luminositätsszenarien tausendmal wiederholt. Die Verteilungen der erhaltenen $\lambda$-Werte zeigen das erwartete gaussförmige Profil, siehe Abbildung \ref{fig:gauss}. Die Breite der angepassten Gaussglocke entspricht dem statistischen Fehler auf den $\lambda$-Wert für die jeweils untersuchte Luminosität. Die Unsicherheiten $\sigma_{\lambda}$ werden gegen die angenommene Luminosität aufgetragen. Die Verteilung ist in Abbildung \ref{fig:sigma_lambda} zu sehen. 

\begin{figure}%
\centering
\includegraphics[width=0.8\columnwidth]{bilder/ensemble}
\caption{Prinzip der Ensemblestudie}%
\label{fig:ensemble}%
\end{figure}

\begin{figure}%
\centering
\begin{subfigure}[b]{0.4\textwidth}
  \includegraphics[width=\textwidth]{bilder/gauss}%
	\caption{Histogrammiertes $\lambda$.}
  \label{fig:gauss}%
\end{subfigure}
\hspace{0.1\textwidth}
\begin{subfigure}[b]{0.4\textwidth}
  \includegraphics[width=\textwidth]{bilder/sigma_lambda}%
	\caption{$\sigma_{\lambda}$ gegen $\mathcal L_{int}$ aufgetragen.}
	\label{fig:sigma_lambda}
\end{subfigure}
\caption{Ergebnisse der Ensemblestudie}%
\end{figure}

$\sigma_{\lambda}$ verringert sich erwartungsgemäß mit steigender Luminosität. l

\subsubsection{Vergleich der verschiedenen Analysemethoden}

Alle drei vorgestellten Analysemethoden zeigen auf Generatorniveau eine klare Abhängigkeit der untersuchten Variablen von $d_A^{\gamma}$. Dabei weisen die 2-Bin-Analyse sowie die Analyse des Schwerpunktes des Photon-$E_T$-Spektrums die größte Separationskraft auf. In der 2-Bin-Analyse liegen zwischen dem Minimal- und dem Maximalwert von $E_{Low}/E_{High}$ rund 50 Standardabweichungen, bei der Analyse von $\overline{E_T}$ sogar 85. Die Analyse der Exponentialanpassung des Photonspektrums weist eine etwas schwächere Separationskraft auf, hier liegen zwischen den Extremwerten von $\lambda$ 19 Standardabweichungen. \\
Die Unsicherheiten auf die Variablen bei der 2-Bin-Analyse und der Mean-Analyse sind proportional zu $1/\sqrt{N}$. Es wird demnach für die Analyse der selektierten Monte-Carlo-Ereignisse und insbesondere für die Analyse von gemessenen Daten eine größere Unsicherheit auf die jeweiligen Variablen erwartet. Die Abhängigkeit der Unsicherheit auf die Exponentialanpassung von der Anzahl der untersuchten Ereignisse ist im Kapitel \ref{sec:ensemble} untersucht worden. Eine deutliche Verringerung der Unsicherheit mit steigender integrierter Luminosität ist zu erkennen. Desweiteren werden zu den hier besprochenen statistischen Unsicherheiten bei der Rekonstruktion und Selektion auch systematische Unsicherheiten entstehen, welche die Separationskraft der analysierten Variablen weiter abnehmen lassen wird, siehe dazu auch Kapitel~\ref{sec:systematiken}.